[project]
name = "clarify-benchmark"
version = "0.1.0"
description = "Benchmarking models for clarification question generation"
readme = "README.md"
requires-python = ">=3.9"

dependencies = [
    "litellm>=1.27.3",
    "python-dotenv",
    "omegaconf",
    "datasets",
    "openai",
    "anthropic",
    "tiktoken",
    "wandb",
    "evaluate",
    "scikit-learn",
    "nltk",
    "bert-score",
    "rouge-score"
]
